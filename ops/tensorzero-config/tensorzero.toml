################################################################################
# TensorZero Gateway Configuration (Dev Profile)
################################################################################

[gateway]
observability.enabled = true
disable_pseudonymous_usage_analytics = true
bind_address = "0.0.0.0:3000"
debug = true
fetch_and_encode_input_files_before_inference = true
# Note: async_writes and batch_writes cannot both be enabled; keep batch writes.
observability.async_writes = false
observability.batch_writes = { enabled = true, flush_interval_ms = 200, max_rows = 500 }


[postgres]
enabled = true
connection_pool_size = 20


# ┌────────────────────────────────────────────────────────────────────────────┐
# │                                   MODELS                                   │
# └────────────────────────────────────────────────────────────────────────────┘


###############################################################################
# Model: Qwen3-8B via Ollama (OpenAI-compatible proxy)
###############################################################################

[models.qwen3_8b]
routing = ["local"]

  [models.qwen3_8b.providers.local]
  type = "openai"
  api_base = "http://host.docker.internal:11434/v1"
  model_name = "qwen3:8b"
  api_key_location = "none"
  #timeouts = { non_streaming.total_ms = 45000, streaming.ttft_ms = 3000 }

###############################################################################
# Embedding Model: Qwen3-Embedding via Ollama
###############################################################################

[models.qwen3_embedding_8b]
routing = ["local"]

  [models.qwen3_embedding_8b.providers.local]
  type = "openai"
  api_base = "http://host.docker.internal:11434/v1"
  model_name = "qwen3-embedding:8b"
  api_key_location = "none"

# ┌────────────────────────────────────────────────────────────────────────────┐
# │                                 FUNCTIONS                                  │
# └────────────────────────────────────────────────────────────────────────────┘

[functions.simple_llm_call]
type = "chat"

[functions.simple_llm_call.variants.baseline]
type = "chat_completion"
model = "qwen3_8b"


[functions.chatbot]
type = "chat"

[functions.chatbot.variants.openai]
type = "chat_completion"
model = "qwen3_embedding_8b"

# ┌────────────────────────────────────────────────────────────────────────────┐
# │                                  METRICS                                   │
# └────────────────────────────────────────────────────────────────────────────┘

[metrics.task_success]
type = "boolean"
optimize = "max"
level = "episode"
